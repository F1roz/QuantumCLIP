{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/F1roz/quantum_clip/blob/main/QuantumCLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHbpGmimEb4p",
        "outputId": "f7fbab4d-4f8b-4ada-d2bd-66b42c27d7b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.39.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.39 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.12.14)\n",
            "Downloading PennyLane-0.39.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 pennylane-0.39.0 pennylane-lightning-0.39.0 rustworkx-0.15.1\n"
          ]
        }
      ],
      "source": [
        "pip install pennylane --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF6aHMqfE--N",
        "outputId": "63194710-87e7-4bbc-f9c5-dfb445a64232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.6.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.1.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=d68c37e6a64ea90a52f186384669385893dc0d28f931f33acd8163f785e73275\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
          ]
        }
      ],
      "source": [
        "pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5sppWACqQTL",
        "outputId": "c66273eb-11a3-41ee-e351-fa43f0d00181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "Successfully installed scikit-learn-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "OC0Hx_U_gMQb",
        "outputId": "9a419de4-f714-4d2c-d951-4994ee464f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/breastmnist.npz?download=1 to /root/.medmnist/breastmnist.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 560k/560k [00:00<00:00, 1.04MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Training samples: 546\n",
            "Test samples: 156\n",
            "Image shape: (546, 28, 28)\n",
            "Labels shape: (546, 1)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First few labels: [1 1 1 1 0 1 1 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from medmnist import BreastMNIST\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# Load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load train dataset\n",
        "train_dataset = BreastMNIST(split='train', transform=data_transform, download=True)\n",
        "test_dataset = BreastMNIST(split='test', transform=data_transform, download=True)\n",
        "\n",
        "# Print dataset info\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(f\"Image shape: {train_dataset.imgs.shape}\")\n",
        "print(f\"Labels shape: {train_dataset.labels.shape}\")\n",
        "\n",
        "# Define captions for visualization\n",
        "captions = {\n",
        "    0: \"benign breast tissue\",\n",
        "    1: \"malignant breast tissue\"\n",
        "}\n",
        "\n",
        "# Visualize some samples\n",
        "def show_samples(dataset, num_samples=5):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        image, label = dataset[i]\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(image.squeeze(), cmap='gray')\n",
        "        plt.title(f\"Label: {captions[label.item()]}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show samples\n",
        "show_samples(train_dataset)\n",
        "\n",
        "# Print first few labels\n",
        "print(\"\\nFirst few labels:\", train_dataset.labels[:10].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLU5lwulFCaa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from medmnist import BreastMNIST\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # Evaluation metrics\n",
        "import os\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple\n",
        "import logging\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import resample\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUQGyi7mFCjT"
      },
      "outputs": [],
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Global configurations\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "class TorchQuantumCircuit(nn.Module):\n",
        "\n",
        "    def __init__(self, n_qubits: int, n_layers: int = 1):\n",
        "        super().__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Trainable parameters for rotation gates\n",
        "        self.weights = nn.Parameter(torch.randn(n_layers, n_qubits, 3))\n",
        "\n",
        "        # Define quantum device and circuit\n",
        "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "        @qml.qnode(self.dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
        "        def quantum_circuit(inputs, weights):\n",
        "            # State preparation\n",
        "            for i in range(self.n_qubits):\n",
        "                qml.RY(inputs[i], wires=i)\n",
        "\n",
        "            # Trainable layers\n",
        "            for layer in range(self.n_layers):\n",
        "                # Rotation gates\n",
        "                for i in range(self.n_qubits):\n",
        "                    qml.RX(weights[layer, i, 0], wires=i)\n",
        "                    qml.RY(weights[layer, i, 1], wires=i)\n",
        "                    qml.RZ(weights[layer, i, 2], wires=i)\n",
        "\n",
        "                # Entanglement\n",
        "                for i in range(self.n_qubits - 1):\n",
        "                    qml.CNOT(wires=[i, i + 1])\n",
        "\n",
        "            # Measurements\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
        "\n",
        "        self.quantum_circuit = quantum_circuit\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        device = x.device\n",
        "\n",
        "        # Process each input in the batch\n",
        "        results = []\n",
        "        for i in range(batch_size):\n",
        "            # Move to CPU for PennyLane processing\n",
        "            inputs = x[i].cpu().detach().numpy()\n",
        "\n",
        "            # Run quantum circuit\n",
        "            output = self.quantum_circuit(inputs, self.weights)\n",
        "            results.append(torch.tensor(output, dtype=torch.float32))\n",
        "\n",
        "        # Stack results and move to original device\n",
        "        return torch.stack(results).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YodkC7mlFCsq"
      },
      "outputs": [],
      "source": [
        "# Part 2: QuantumCLIP Implementation\n",
        "\n",
        "class QuantumCLIP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 temperature: float = 0.07,\n",
        "                 n_qubits: int = 4,\n",
        "                 n_layers: int = 1,\n",
        "                 embedding_dim: int = 512):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Text encoder\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.text_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.text_projection = nn.Linear(768, embedding_dim)\n",
        "\n",
        "        # Image encoder with quantum circuit\n",
        "        self.image_encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 128, dtype=torch.float32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64, dtype=torch.float32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_qubits, dtype=torch.float32),\n",
        "            nn.Tanh(),  # Normalize inputs to quantum circuit\n",
        "            TorchQuantumCircuit(n_qubits=n_qubits, n_layers=n_layers),\n",
        "            nn.Linear(n_qubits, embedding_dim, dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "\n",
        "        # Temperature parameter\n",
        "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / temperature))\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def encode_text(self, text: List[str]) -> torch.Tensor:\n",
        "        # Tokenize and encode text\n",
        "        text_tokens = self.tokenizer(\n",
        "            text,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=77,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(next(self.parameters()).device)\n",
        "\n",
        "        # Get text features\n",
        "        text_features = self.text_encoder(**text_tokens).last_hidden_state[:, 0, :]\n",
        "        text_features = self.text_projection(text_features)\n",
        "\n",
        "        return nn.functional.normalize(text_features, dim=-1)\n",
        "\n",
        "    def encode_image(self, image: torch.Tensor) -> torch.Tensor:\n",
        "        # Flatten and encode image\n",
        "        image_features = self.image_encoder(image.view(-1, 28*28))\n",
        "        return nn.functional.normalize(image_features, dim=-1)\n",
        "\n",
        "    def forward(self, image: torch.Tensor, text: List[str]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Get image and text features\n",
        "        image_features = self.encode_image(image)\n",
        "        text_features = self.encode_text(text)\n",
        "\n",
        "        # Calculate similarity\n",
        "        logit_scale = self.logit_scale.exp()\n",
        "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
        "        logits_per_text = logits_per_image.t()\n",
        "\n",
        "        return logits_per_image, logits_per_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwDpZxeUFCzq"
      },
      "outputs": [],
      "source": [
        "class BreastDataset(Dataset):\n",
        "    def __init__(self, split='train'):\n",
        "        # Initialize and download the BreastMNIST dataset\n",
        "        data = BreastMNIST(split=split, download=True)\n",
        "        self.images = data.imgs\n",
        "        self.labels = data.labels\n",
        "        # Define image transformations\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        # Define detailed class descriptions for mammogram findings\n",
        "        self.class_descriptions = {\n",
        "            'normal': \"This mammogram shows normal breast tissue with no suspicious findings or abnormalities\",\n",
        "            'malignant': \"This mammogram shows suspicious findings indicating possible breast cancer with abnormal tissue patterns\"\n",
        "        }\n",
        "\n",
        "        # Initialize lists for storing descriptions and labels\n",
        "        self.descriptions = []\n",
        "        self.binary_labels = []\n",
        "\n",
        "        # Process each image's label and create corresponding description\n",
        "        for label in self.labels:\n",
        "            # Convert tensor to boolean (0 = normal, 1 = malignant)\n",
        "            is_malignant = bool(label.item())\n",
        "            # Get corresponding description\n",
        "            description = self.class_descriptions['malignant' if is_malignant else 'normal']\n",
        "\n",
        "            # Store description and label\n",
        "            self.descriptions.append(description)\n",
        "            self.binary_labels.append(int(is_malignant))\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return total number of samples\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get single item from dataset\n",
        "        image = self.transform(self.images[idx])  # Transform image to tensor\n",
        "        text = self.descriptions[idx]             # Get corresponding description\n",
        "        label = self.binary_labels[idx]          # Get binary label\n",
        "        return image, text, label\n",
        "\n",
        "def calculate_similarity_metrics(logits_per_image):\n",
        "    \"\"\"\n",
        "    Calculate various similarity metrics between image and text pairs\n",
        "    \"\"\"\n",
        "    # Get batch size from input\n",
        "    batch_size = logits_per_image.size(0)\n",
        "\n",
        "    # Calculate similarity for matched pairs (diagonal elements)\n",
        "    diagonal_similarities = torch.diagonal(logits_per_image)\n",
        "    avg_matched_similarity = diagonal_similarities.mean().item()\n",
        "\n",
        "    # Calculate similarity for unmatched pairs (non-diagonal elements)\n",
        "    mask = ~torch.eye(batch_size, dtype=bool, device=logits_per_image.device)\n",
        "    unmatched_similarities = logits_per_image[mask]\n",
        "    avg_unmatched_similarity = unmatched_similarities.mean().item()\n",
        "\n",
        "    # Return computed metrics\n",
        "    return {\n",
        "        'avg_matched_similarity': avg_matched_similarity,\n",
        "        'avg_unmatched_similarity': avg_unmatched_similarity,\n",
        "        'similarity_ratio': avg_matched_similarity / avg_unmatched_similarity\n",
        "    }\n",
        "\n",
        "def evaluate_model(model, val_loader, device):\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Initialize lists for storing predictions and actual labels\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_similarity_metrics = []\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        for images, texts, labels in val_loader:\n",
        "            # Move images to device (GPU/CPU)\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            logits_per_image, _ = model(images, texts)\n",
        "\n",
        "            # Convert logits to binary predictions\n",
        "            preds = (logits_per_image.argmax(dim=1) == 1).cpu().numpy()\n",
        "            labels = np.array(labels)\n",
        "\n",
        "            # Calculate similarity metrics for this batch\n",
        "            similarity_metrics = calculate_similarity_metrics(logits_per_image)\n",
        "            all_similarity_metrics.append(similarity_metrics)\n",
        "\n",
        "            # Store predictions and labels\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    # Calculate classification metrics\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(all_labels, all_preds),\n",
        "        'precision': precision_score(all_labels, all_preds, average='binary'),\n",
        "        'recall': recall_score(all_labels, all_preds, average='binary'),\n",
        "        'f1': f1_score(all_labels, all_preds, average='binary')\n",
        "    }\n",
        "\n",
        "    # Calculate average similarity metrics across all batches\n",
        "    avg_similarity_metrics = {\n",
        "        'avg_matched_similarity': np.mean([m['avg_matched_similarity'] for m in all_similarity_metrics]),\n",
        "        'avg_unmatched_similarity': np.mean([m['avg_unmatched_similarity'] for m in all_similarity_metrics]),\n",
        "        'similarity_ratio': np.mean([m['similarity_ratio'] for m in all_similarity_metrics])\n",
        "    }\n",
        "\n",
        "    # Combine all metrics\n",
        "    metrics.update(avg_similarity_metrics)\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzFG_0NqO89-",
        "outputId": "b2c1ae8c-7de4-47b1-be03-de995e291bed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.001, 'temperature': 0.07, 'weight_decay': 0.01}\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 0: Loss = 2.7275, F1 = 0.2083\n",
            "Epoch 1: Loss = 2.7243, F1 = 0.2857\n",
            "Epoch 2: Loss = 2.7244, F1 = 0.2857\n",
            "Epoch 3: Loss = 2.7229, F1 = 0.2857\n",
            "Epoch 4: Loss = 2.7235, F1 = 0.2128\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 0: Loss = 2.7365, F1 = 0.2083\n",
            "Epoch 1: Loss = 2.7356, F1 = 0.3119\n",
            "Epoch 2: Loss = 2.7331, F1 = 0.3137\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3499\n",
            "precision: 0.6196\n",
            "recall: 0.1722\n",
            "f1: 0.2570\n",
            "avg_matched_similarity: -2.2697\n",
            "avg_unmatched_similarity: -2.2697\n",
            "similarity_ratio: 0.9995\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.001, 'temperature': 0.07, 'weight_decay': 0.001}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3059\n",
            "precision: 0.6789\n",
            "recall: 0.0858\n",
            "f1: 0.1512\n",
            "avg_matched_similarity: -2.8715\n",
            "avg_unmatched_similarity: -2.8715\n",
            "similarity_ratio: 1.0000\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.001, 'temperature': 0.1, 'weight_decay': 0.01}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.4177\n",
            "precision: 0.5643\n",
            "recall: 0.3303\n",
            "f1: 0.4082\n",
            "avg_matched_similarity: 0.5844\n",
            "avg_unmatched_similarity: 0.5836\n",
            "similarity_ratio: 1.0010\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.001, 'temperature': 0.1, 'weight_decay': 0.001}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3534\n",
            "precision: 0.7750\n",
            "recall: 0.1666\n",
            "f1: 0.2722\n",
            "avg_matched_similarity: -2.8677\n",
            "avg_unmatched_similarity: -2.8677\n",
            "similarity_ratio: 1.0000\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.0005, 'temperature': 0.07, 'weight_decay': 0.01}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3021\n",
            "precision: 0.6266\n",
            "recall: 0.1368\n",
            "f1: 0.2182\n",
            "avg_matched_similarity: 0.5497\n",
            "avg_unmatched_similarity: 0.5497\n",
            "similarity_ratio: 1.0000\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.0005, 'temperature': 0.07, 'weight_decay': 0.001}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3186\n",
            "precision: 0.5934\n",
            "recall: 0.1026\n",
            "f1: 0.1711\n",
            "avg_matched_similarity: 1.1386\n",
            "avg_unmatched_similarity: 1.1386\n",
            "similarity_ratio: 1.0000\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.0005, 'temperature': 0.1, 'weight_decay': 0.01}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3224\n",
            "precision: 0.6071\n",
            "recall: 0.1199\n",
            "f1: 0.1867\n",
            "avg_matched_similarity: 0.2122\n",
            "avg_unmatched_similarity: 0.2111\n",
            "similarity_ratio: 1.0005\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.0005, 'temperature': 0.1, 'weight_decay': 0.001}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3919\n",
            "precision: 0.7146\n",
            "recall: 0.2616\n",
            "f1: 0.3805\n",
            "avg_matched_similarity: -1.3295\n",
            "avg_unmatched_similarity: -1.3295\n",
            "similarity_ratio: 1.0000\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.0001, 'temperature': 0.07, 'weight_decay': 0.01}\n",
            "\n",
            "Fold 1/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 2/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 3/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 4/5\n",
            "Early stopping triggered\n",
            "\n",
            "Fold 5/5\n",
            "Early stopping triggered\n",
            "\n",
            "Average metrics across folds:\n",
            "accuracy: 0.3589\n",
            "precision: 0.7817\n",
            "recall: 0.1934\n",
            "f1: 0.2776\n",
            "avg_matched_similarity: -0.1740\n",
            "avg_unmatched_similarity: -0.1743\n",
            "similarity_ratio: 1.0003\n",
            "\n",
            "Trying parameters: {'batch_size': 16, 'learning_rate': 0.0001, 'temperature': 0.07, 'weight_decay': 0.001}\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 0: Loss = 2.7228, F1 = 0.0000\n",
            "Epoch 1: Loss = 2.7426, F1 = 0.2045\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "def train_quantum_clip(): #hyperparameter tuning added, cross validation, early stopping\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Hyperparameter grid\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.001, 0.0005, 0.0001],\n",
        "        'batch_size': [16, 32],\n",
        "        'weight_decay': [0.01, 0.001],\n",
        "        'temperature': [0.07, 0.1]\n",
        "    }\n",
        "\n",
        "    # Cross-validation setup\n",
        "    n_splits = 5\n",
        "    kfold = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    early_stopping_patience = 5\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Track best model and parameters\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "    best_metrics = None\n",
        "    best_overall_f1 = 0.0\n",
        "\n",
        "    # Dataset preparation\n",
        "    dataset = BreastDataset(split='train')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"\\nTrying parameters: {params}\")\n",
        "        cv_metrics = []\n",
        "\n",
        "        # Cross-validation loop\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "            print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
        "\n",
        "            # Create data loaders for this fold\n",
        "            train_subsampler = SubsetRandomSampler(train_idx)\n",
        "            val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "            train_loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=params['batch_size'],\n",
        "                sampler=train_subsampler\n",
        "            )\n",
        "            val_loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=params['batch_size'],\n",
        "                sampler=val_subsampler\n",
        "            )\n",
        "\n",
        "            # Initialize model\n",
        "            model = QuantumCLIP(temperature=params['temperature']).to(device)\n",
        "\n",
        "            # Initialize optimizer and scheduler\n",
        "            optimizer = optim.Adam(\n",
        "                model.parameters(),\n",
        "                lr=params['learning_rate'],\n",
        "                weight_decay=params['weight_decay']\n",
        "            )\n",
        "\n",
        "            # Learning rate scheduler\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer,\n",
        "                mode='min',\n",
        "                factor=0.5,\n",
        "                patience=2,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "            # Training history\n",
        "            history = {\n",
        "                'train_loss': [],\n",
        "                'val_metrics': []\n",
        "            }\n",
        "\n",
        "            # Training loop\n",
        "            for epoch in range(5):  # Max epochs\n",
        "                # Training phase\n",
        "                model.train()\n",
        "                total_loss = 0\n",
        "\n",
        "                for batch_idx, (images, texts, _) in enumerate(train_loader):\n",
        "                    images = images.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    logits_per_image, logits_per_text = model(images, texts)\n",
        "\n",
        "                    ground_truth = torch.arange(len(images)).to(device)\n",
        "                    loss = (criterion(logits_per_image, ground_truth) +\n",
        "                           criterion(logits_per_text, ground_truth)) / 2\n",
        "\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                avg_loss = total_loss / len(train_loader)\n",
        "                history['train_loss'].append(avg_loss)\n",
        "\n",
        "                # Validation phase\n",
        "                val_metrics = evaluate_model(model, val_loader, device)\n",
        "                history['val_metrics'].append(val_metrics)\n",
        "\n",
        "                # Learning rate scheduling\n",
        "                scheduler.step(avg_loss)\n",
        "\n",
        "                # Early stopping check\n",
        "                if avg_loss < best_val_loss:\n",
        "                    best_val_loss = avg_loss\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= early_stopping_patience:\n",
        "                    print(\"Early stopping triggered\")\n",
        "                    break\n",
        "\n",
        "                print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}, F1 = {val_metrics['f1']:.4f}\")\n",
        "\n",
        "            # Store fold metrics\n",
        "            cv_metrics.append(val_metrics)\n",
        "\n",
        "        # Calculate average metrics across folds\n",
        "        avg_metrics = {\n",
        "            metric: np.mean([fold[metric] for fold in cv_metrics])\n",
        "            for metric in cv_metrics[0].keys()\n",
        "        }\n",
        "\n",
        "        print(\"\\nAverage metrics across folds:\")\n",
        "        for metric, value in avg_metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "        # Update best model if better\n",
        "        if avg_metrics['f1'] > best_overall_f1:\n",
        "            best_overall_f1 = avg_metrics['f1']\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_params = params\n",
        "            best_metrics = avg_metrics\n",
        "\n",
        "    # Save best model and parameters\n",
        "    torch.save({\n",
        "        'model_state_dict': best_model.state_dict(),\n",
        "        'hyperparameters': best_params,\n",
        "        'metrics': best_metrics\n",
        "    }, 'best_quantum_clip_model.pth')\n",
        "\n",
        "    print(\"\\nBest hyperparameters:\", best_params)\n",
        "    print(\"\\nBest metrics:\", best_metrics)\n",
        "\n",
        "    return best_model, best_params, best_metrics\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    best_model, best_params, best_metrics = train_quantum_clip()\n",
        "\n",
        "    # Test evaluation\n",
        "    test_dataset = BreastDataset(split='test')\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    test_metrics = evaluate_model(best_model, test_loader, device)\n",
        "    print(\"\\nTest Results with Best Model:\")\n",
        "    for metric, value in test_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Visualize predictions\n",
        "    visualize_predictions(best_model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLw2f81lFC7b",
        "outputId": "9bb600c5-dbe6-494a-e381-b4b01689ef92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Epoch: 0, Batch: 0, Loss: 3.4773\n",
            "Epoch: 0, Batch: 10, Loss: 3.4682\n",
            "\n",
            "Epoch 0 completed:\n",
            "Average Loss: 3.3168\n",
            "Validation Metrics:\n",
            "Accuracy: 0.4615\n",
            "Precision: 0.8000\n",
            "Recall: 0.3509\n",
            "F1 Score: 0.4878\n",
            "Similarity Ratio: 1.0031\n",
            "--------------------------------------------------\n",
            "Epoch: 1, Batch: 0, Loss: 3.4184\n",
            "Epoch: 1, Batch: 10, Loss: 3.4541\n",
            "\n",
            "Epoch 1 completed:\n",
            "Average Loss: 3.3101\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3974\n",
            "Precision: 0.8125\n",
            "Recall: 0.2281\n",
            "F1 Score: 0.3562\n",
            "Similarity Ratio: 1.0002\n",
            "--------------------------------------------------\n",
            "Epoch: 2, Batch: 0, Loss: 3.4677\n",
            "Epoch: 2, Batch: 10, Loss: 3.4627\n",
            "\n",
            "Epoch 2 completed:\n",
            "Average Loss: 3.3121\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3718\n",
            "Precision: 0.6818\n",
            "Recall: 0.2632\n",
            "F1 Score: 0.3797\n",
            "Similarity Ratio: 1.0003\n",
            "--------------------------------------------------\n",
            "Epoch: 3, Batch: 0, Loss: 3.4633\n",
            "Epoch: 3, Batch: 10, Loss: 3.4648\n",
            "\n",
            "Epoch 3 completed:\n",
            "Average Loss: 3.3092\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3462\n",
            "Precision: 0.6875\n",
            "Recall: 0.1930\n",
            "F1 Score: 0.3014\n",
            "Similarity Ratio: 1.0031\n",
            "--------------------------------------------------\n",
            "Epoch: 4, Batch: 0, Loss: 3.4570\n",
            "Epoch: 4, Batch: 10, Loss: 3.4610\n",
            "\n",
            "Epoch 4 completed:\n",
            "Average Loss: 3.2878\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3846\n",
            "Precision: 0.6800\n",
            "Recall: 0.2982\n",
            "F1 Score: 0.4146\n",
            "Similarity Ratio: 1.0054\n",
            "--------------------------------------------------\n",
            "Epoch: 5, Batch: 0, Loss: 3.4244\n",
            "Epoch: 5, Batch: 10, Loss: 3.4027\n",
            "\n",
            "Epoch 5 completed:\n",
            "Average Loss: 3.3086\n",
            "Validation Metrics:\n",
            "Accuracy: 0.2821\n",
            "Precision: 0.5455\n",
            "Recall: 0.1053\n",
            "F1 Score: 0.1765\n",
            "Similarity Ratio: 1.0002\n",
            "--------------------------------------------------\n",
            "Epoch: 6, Batch: 0, Loss: 3.4665\n",
            "Epoch: 6, Batch: 10, Loss: 3.4693\n",
            "\n",
            "Epoch 6 completed:\n",
            "Average Loss: 3.3122\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3846\n",
            "Precision: 0.6957\n",
            "Recall: 0.2807\n",
            "F1 Score: 0.4000\n",
            "Similarity Ratio: 1.0000\n",
            "--------------------------------------------------\n",
            "Epoch: 7, Batch: 0, Loss: 3.4693\n",
            "Epoch: 7, Batch: 10, Loss: 3.4665\n",
            "\n",
            "Epoch 7 completed:\n",
            "Average Loss: 3.3129\n",
            "Validation Metrics:\n",
            "Accuracy: 0.4103\n",
            "Precision: 0.7200\n",
            "Recall: 0.3158\n",
            "F1 Score: 0.4390\n",
            "Similarity Ratio: 1.0000\n",
            "--------------------------------------------------\n",
            "Epoch: 8, Batch: 0, Loss: 3.4673\n",
            "Epoch: 8, Batch: 10, Loss: 3.4664\n",
            "\n",
            "Epoch 8 completed:\n",
            "Average Loss: 3.3130\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3205\n",
            "Precision: 1.0000\n",
            "Recall: 0.0702\n",
            "F1 Score: 0.1311\n",
            "Similarity Ratio: 1.0000\n",
            "--------------------------------------------------\n",
            "Epoch: 9, Batch: 0, Loss: 3.4639\n",
            "Epoch: 9, Batch: 10, Loss: 3.4689\n",
            "\n",
            "Epoch 9 completed:\n",
            "Average Loss: 3.3124\n",
            "Validation Metrics:\n",
            "Accuracy: 0.3205\n",
            "Precision: 0.8333\n",
            "Recall: 0.0877\n",
            "F1 Score: 0.1587\n",
            "Similarity Ratio: 1.0000\n",
            "--------------------------------------------------\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "\n",
            "Final Test Results:\n",
            "Accuracy: 0.3590\n",
            "Precision: 0.6944\n",
            "Recall: 0.2193\n",
            "F1 Score: 0.3333\n",
            "Similarity Ratio: 1.0001\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'malignant_prob' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b5850296829b>\u001b[0m in \u001b[0;36m<cell line: 154>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# Visualize predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mvisualize_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-b5850296829b>\u001b[0m in \u001b[0;36mvisualize_predictions\u001b[0;34m(model, test_loader, device, num_samples)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Malignant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmalignant_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmalignant_prob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction Probabilities'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'malignant_prob' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def train_quantum_clip(): #without hyperparameter tuning\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = QuantumCLIP().to(device)\n",
        "\n",
        "    # Initialize datasets\n",
        "    train_dataset = BreastDataset(split='train')\n",
        "    val_dataset = BreastDataset(split='val')\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Initialize loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Initialize dictionary to store training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_metrics': []\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        total_loss = 0\n",
        "\n",
        "        # Batch training\n",
        "        for batch_idx, (images, texts, _) in enumerate(train_loader):\n",
        "            # Move images to device\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits_per_image, logits_per_text = model(images, texts)\n",
        "\n",
        "            # Calculate ground truth (diagonal matrix)\n",
        "            ground_truth = torch.arange(len(images)).to(device)\n",
        "\n",
        "            # Calculate symmetric loss (image-to-text and text-to-image)\n",
        "            loss = (criterion(logits_per_image, ground_truth) +\n",
        "                   criterion(logits_per_text, ground_truth)) / 2\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Print progress every 10 batches\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Calculate average loss for epoch\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        history['train_loss'].append(avg_loss)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "        history['val_metrics'].append(val_metrics)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch} completed:\")\n",
        "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "        print(f\"Validation Metrics:\")\n",
        "        print(f\"Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "        print(f\"Precision: {val_metrics['precision']:.4f}\")\n",
        "        print(f\"Recall: {val_metrics['recall']:.4f}\")\n",
        "        print(f\"F1 Score: {val_metrics['f1']:.4f}\")\n",
        "        print(f\"Similarity Ratio: {val_metrics['similarity_ratio']:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Visualization of training history\n",
        "    def plot_training_history():\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Plot training loss\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(history['train_loss'])\n",
        "        plt.title('Training Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "\n",
        "        # Plot classification metrics\n",
        "        plt.subplot(1, 3, 2)\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "        for metric in metrics:\n",
        "            values = [epoch_metrics[metric] for epoch_metrics in history['val_metrics']]\n",
        "            plt.plot(values, label=metric)\n",
        "        plt.title('Classification Metrics')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Score')\n",
        "        plt.legend()\n",
        "\n",
        "        # Plot similarity metrics\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot([m['similarity_ratio'] for m in history['val_metrics']],\n",
        "                label='Similarity Ratio')\n",
        "        plt.title('Similarity Metrics')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Ratio')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_history.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Plot the training history\n",
        "    plot_training_history()\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def visualize_predictions(model, test_loader, device, num_samples=5):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Get sample batch\n",
        "    images, texts, labels = next(iter(test_loader))\n",
        "    images = images.to(device)[:num_samples]\n",
        "    texts = texts[:num_samples]\n",
        "    labels = labels[:num_samples]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits_per_image, _ = model(images, texts)\n",
        "        probs = torch.softmax(logits_per_image, dim=1)\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(15, 3*num_samples))\n",
        "    for idx in range(num_samples):\n",
        "        plt.subplot(num_samples, 2, 2*idx + 1)\n",
        "        plt.imshow(images[idx].cpu().squeeze(), cmap='gray')\n",
        "        plt.title(f\"True: {'Malignant' if labels[idx] else 'Normal'}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2*idx + 2)\n",
        "        plt.bar(['Normal', 'Malignant'], [1 - malignant_prob, malignant_prob])\n",
        "        plt.title('Prediction Probabilities')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('predictions_visualization.png')\n",
        "    plt.close()\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Train model\n",
        "    model, history = train_quantum_clip()\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'quantum_clip_model.pth')\n",
        "\n",
        "    # Create test dataset and loader\n",
        "    test_dataset = BreastDataset(split='test')\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    test_metrics = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # Print final test results\n",
        "    print(\"\\nFinal Test Results:\")\n",
        "    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n",
        "    print(f\"Similarity Ratio: {test_metrics['similarity_ratio']:.4f}\")\n",
        "\n",
        "    # Visualize predictions\n",
        "    visualize_predictions(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLiwOPB6HEss"
      },
      "outputs": [],
      "source": [
        "def plot_breast_similarity(model, test_loader, device, num_samples=5):\n",
        "\n",
        "\n",
        "\n",
        "    # Get breast images and their descriptions\n",
        "    images, texts, labels = next(iter(test_loader))\n",
        "    images = images[:num_samples].to(device)\n",
        "    texts = texts[:num_samples]\n",
        "\n",
        "    # Create simplified descriptions for visualization\n",
        "    short_texts = [\n",
        "        \"Normal\" if label == 0 else \"Malignant\"\n",
        "        for label in labels[:num_samples]\n",
        "    ]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get image and text features\n",
        "        image_features = model.visual_encoder(images.view(-1, 28*28))\n",
        "        text_inputs = model.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        text_features = model.text_encoder(**text_inputs).last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Normalize features\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # Calculate similarity\n",
        "        similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(20, 14))\n",
        "    plt.imshow(similarity, vmin=0.1, vmax=0.3)\n",
        "    plt.yticks(range(len(short_texts)), short_texts, fontsize=18)\n",
        "    plt.xticks([])\n",
        "\n",
        "    # Display breast images below\n",
        "    for i, img in enumerate(images):\n",
        "        plt.imshow(img.cpu().squeeze(), extent=(i-0.5, i+0.5, -1.6, -0.6), cmap='gray')\n",
        "\n",
        "    # Add similarity values\n",
        "    for i in range(similarity.shape[1]):\n",
        "        for j in range(similarity.shape[0]):\n",
        "            plt.text(i, j, f\"{similarity[j, i]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
        "\n",
        "    plt.title(\"Breast Image-Text Similarity (Quantum-CLIP)\", size=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('breast_similarity.png')\n",
        "    plt.close()\n",
        "\n",
        "# Usage\n",
        "plot_breast_similarity(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XYuI85XQFDM_",
        "outputId": "46a19090-6067-43c2-bd7b-a01a3a9b265c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 6, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 1e-05, 'n_qubits': 8, 'projection_dim': 1024, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 256, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 1, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 2, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.07}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 512, 'quantum_layers': 3, 'temperature': 0.1}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Error with parameters {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.01}: Module [QuantumCLIP] is missing the required \"forward\" function\n",
            "\n",
            "Testing parameters: {'batch_size': 16, 'learning_rate': 5e-05, 'n_qubits': 4, 'projection_dim': 1024, 'quantum_layers': 1, 'temperature': 0.07}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4cea046be077>\u001b[0m in \u001b[0;36m<cell line: 175>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# Perform hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mbest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# Print best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4cea046be077>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Create model with current parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             model = QuantumCLIP(\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mn_qubits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_qubits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4cea046be077>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, temperature, n_qubits, quantum_layers, projection_dim)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Text encoder components remain the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_projection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2030\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2032\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2033\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2270\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2272\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2273\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mimport_protobuf_decode_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m             logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;34m\" model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             )\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids_to_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mload_vocab\u001b[0;34m(vocab_file)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#hyperparameter tuning\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def hyperparameter_tuning():\n",
        "\n",
        "    # Define hyperparameter grid\n",
        "    param_grid = {\n",
        "        'learning_rate': [1e-5, 5e-5, 1e-4],\n",
        "        'batch_size': [16, 32, 64],\n",
        "        'temperature': [0.01, 0.07, 0.1],\n",
        "        'n_qubits': [4, 6, 8],\n",
        "        'quantum_layers': [1, 2, 3],  # Number of quantum circuit layers\n",
        "        'projection_dim': [256, 512, 1024]  # Dimension of the projection space\n",
        "    }\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    results = []\n",
        "\n",
        "    # Create parameter combinations\n",
        "    param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "    # Create validation dataset\n",
        "    val_dataset = BreastDataset(split='val')\n",
        "\n",
        "    # Loop through parameter combinations\n",
        "    for params in param_combinations:\n",
        "        try:\n",
        "            print(f\"\\nTesting parameters: {params}\")\n",
        "\n",
        "            # Create model with current parameters\n",
        "            model = QuantumCLIP(\n",
        "                temperature=params['temperature'],\n",
        "                n_qubits=params['n_qubits'],\n",
        "                quantum_layers=params['quantum_layers'],\n",
        "                projection_dim=params['projection_dim']\n",
        "            ).to(device)\n",
        "\n",
        "            # Create data loaders\n",
        "            train_dataset = BreastDataset(split='train')\n",
        "            train_loader = DataLoader(train_dataset,\n",
        "                                    batch_size=params['batch_size'],\n",
        "                                    shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset,\n",
        "                                  batch_size=params['batch_size'],\n",
        "                                  shuffle=False)\n",
        "\n",
        "            # Initialize optimizer\n",
        "            optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
        "\n",
        "            # Train for a few epochs\n",
        "            num_epochs = 5  # Reduced epochs for quick evaluation\n",
        "            best_val_metrics = train_and_evaluate(\n",
        "                model, train_loader, val_loader, optimizer, num_epochs\n",
        "            )\n",
        "\n",
        "            # Store results\n",
        "            result = {\n",
        "                'parameters': params,\n",
        "                'metrics': best_val_metrics,\n",
        "                'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # Save intermediate results\n",
        "            save_tuning_results(results)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with parameters {params}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Find best parameters\n",
        "    best_result = max(results, key=lambda x: x['metrics']['f1'])\n",
        "    return best_result\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, optimizer, num_epochs):\n",
        "    \"\"\"\n",
        "    Training function for hyperparameter tuning\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_metrics = None\n",
        "    best_f1 = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for images, texts, _ in train_loader:\n",
        "            images = images.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits_per_image, logits_per_text = model(images, texts)\n",
        "            ground_truth = torch.arange(len(images)).to(device)\n",
        "\n",
        "            loss = (criterion(logits_per_image, ground_truth) +\n",
        "                   criterion(logits_per_text, ground_truth)) / 2\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "\n",
        "        # Update best metrics\n",
        "        if val_metrics['f1'] > best_f1:\n",
        "            best_f1 = val_metrics['f1']\n",
        "            best_metrics = val_metrics\n",
        "\n",
        "    return best_metrics\n",
        "\n",
        "def save_tuning_results(results):\n",
        "    \"\"\"\n",
        "    Save hyperparameter tuning results to file\n",
        "    \"\"\"\n",
        "    filename = f\"hyperparameter_tuning_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=4, default=str)\n",
        "\n",
        "def visualize_tuning_results(results):\n",
        "    \"\"\"\n",
        "    Visualize hyperparameter tuning results\n",
        "    \"\"\"\n",
        "    # Create plots for each hyperparameter\n",
        "    params_to_plot = ['learning_rate', 'batch_size', 'temperature', 'n_qubits']\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, param in enumerate(params_to_plot, 1):\n",
        "        plt.subplot(2, 2, i)\n",
        "\n",
        "        # Extract parameter values and corresponding F1 scores\n",
        "        param_values = [r['parameters'][param] for r in results]\n",
        "        f1_scores = [r['metrics']['f1'] for r in results]\n",
        "\n",
        "        # Plot\n",
        "        plt.scatter(param_values, f1_scores)\n",
        "        plt.xlabel(param)\n",
        "        plt.ylabel('F1 Score')\n",
        "        plt.title(f'F1 Score vs {param}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('hyperparameter_tuning_results.png')\n",
        "    plt.close()\n",
        "\n",
        "# Modified QuantumCLIP class to accept hyperparameters\n",
        "class QuantumCLIP(nn.Module):\n",
        "    def __init__(self, temperature=0.07, n_qubits=4, quantum_layers=1, projection_dim=512):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_qubits = n_qubits\n",
        "        self.quantum_layers = quantum_layers\n",
        "\n",
        "        # Text encoder components remain the same\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.text_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.text_projection = nn.Linear(768, projection_dim, dtype=torch.float32)\n",
        "\n",
        "        # Modified quantum encoder\n",
        "        self.quantum_encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 32, dtype=torch.float32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, n_qubits, dtype=torch.float32),\n",
        "            *[QuantumCircuit(n_qubits) for _ in range(quantum_layers)],\n",
        "            nn.Linear(n_qubits, projection_dim, dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "        self.logit_scale = nn.Parameter(torch.ones([], dtype=torch.float32) * np.log(1 / temperature))\n",
        "\n",
        "# Main execution for hyperparameter tuning\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Perform hyperparameter tuning\n",
        "    best_result = hyperparameter_tuning()\n",
        "\n",
        "    # Print best parameters\n",
        "    print(\"\\nBest Parameters:\")\n",
        "    print(json.dumps(best_result['parameters'], indent=4))\n",
        "    print(\"\\nBest Metrics:\")\n",
        "    print(json.dumps(best_result['metrics'], indent=4))\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_tuning_results(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAgcJqQxssMEGUNER6vAJh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}